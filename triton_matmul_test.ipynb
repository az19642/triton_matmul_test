{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaVP-8FBO6ZY",
        "outputId": "4f608497-be15-4df4-d75f-f03d9dbc3b3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl"
      ],
      "metadata": {
        "id": "oxHtnyOsOxW_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_autotune_config():\n",
        "    return [\n",
        "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}),\n",
        "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8})\n",
        "    ]\n",
        "\n",
        "def get_autotune_config_alt():\n",
        "    return [\n",
        "        triton.Config(\n",
        "            {\n",
        "                \"BLOCK_SIZE_M\": BLOCK_SIZE_M,\n",
        "                \"BLOCK_SIZE_N\": BLOCK_SIZE_N,\n",
        "                \"BLOCK_SIZE_K\": BLOCK_SIZE_K,\n",
        "                \"GROUP_SIZE_M\": GROUP_SIZE_M,\n",
        "            }\n",
        "        )\n",
        "        for BLOCK_SIZE_M in [32, 64, 128]\n",
        "        for BLOCK_SIZE_N in [32, 64, 128]\n",
        "        for BLOCK_SIZE_K in [32, 64, 128]\n",
        "        for GROUP_SIZE_M in [8, 16, 32]\n",
        "    ]"
      ],
      "metadata": {
        "id": "S3YXg-B0q0Cs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.autotune(\n",
        "    configs=get_autotune_config(),\n",
        "    key=[\"K\"],\n",
        ")\n",
        "@triton.jit\n",
        "def matmul_kernel(\n",
        "    a_ptr,\n",
        "    b_ptr,\n",
        "    c_ptr,\n",
        "    M,\n",
        "    N,\n",
        "    K,\n",
        "    stride_am,\n",
        "    stride_ak,\n",
        "    stride_bk,\n",
        "    stride_bn,\n",
        "    stride_cm,\n",
        "    stride_cn,\n",
        "    BLOCK_SIZE_M: tl.constexpr,\n",
        "    BLOCK_SIZE_N: tl.constexpr,\n",
        "    BLOCK_SIZE_K: tl.constexpr,\n",
        "    GROUP_SIZE_M: tl.constexpr,\n",
        "):\n",
        "    \"\"\"Kernel for computing the matmul C = A x B.\n",
        "    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n",
        "    \"\"\"\n",
        "    pid = tl.program_id(axis=0)\n",
        "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
        "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
        "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
        "    group_id = pid // num_pid_in_group\n",
        "    first_pid_m = group_id * GROUP_SIZE_M\n",
        "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
        "    pid_m = first_pid_m + (pid % group_size_m)\n",
        "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
        "\n",
        "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
        "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
        "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
        "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
        "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
        "\n",
        "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
        "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
        "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
        "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
        "        accumulator = tl.dot(a, b, accumulator)\n",
        "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
        "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
        "    c = accumulator.to(tl.float16)\n",
        "\n",
        "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
        "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
        "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
        "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
        "    tl.store(c_ptrs, c, mask=c_mask)"
      ],
      "metadata": {
        "id": "DXUqFPViqvue"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul(a, b):\n",
        "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
        "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
        "    M, K = a.shape\n",
        "    K, N = b.shape\n",
        "\n",
        "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
        "    grid = lambda META: (\n",
        "        triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"]),\n",
        "    )\n",
        "    matmul_kernel[grid](\n",
        "        a,\n",
        "        b,\n",
        "        c,\n",
        "        M,\n",
        "        N,\n",
        "        K,\n",
        "        a.stride(0),\n",
        "        a.stride(1),\n",
        "        b.stride(0),\n",
        "        b.stride(1),\n",
        "        c.stride(0),\n",
        "        c.stride(1),\n",
        "    )\n",
        "    return c"
      ],
      "metadata": {
        "id": "nT3dH6IirXST"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.testing.perf_report(\n",
        "    [\n",
        "        triton.testing.Benchmark(\n",
        "            x_names=[\"K\"],\n",
        "            x_vals=[i for i in range(512, 540)],  # change to range(512, 8913)\n",
        "            line_arg=\"provider\",\n",
        "            line_vals=[\"cublas\", \"triton\"],\n",
        "            line_names=[\"cuBLAS\", \"Triton\"],\n",
        "            styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
        "            ylabel=\"Time (ms)\",\n",
        "            plot_name=\"matmul-performance-\" + (\"fp16\"),\n",
        "            args={\"M\": 8192, \"N\": 8192},\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "def benchmark(M, N, K, provider):\n",
        "    a = torch.randn((M, K), device=\"cuda\", dtype=torch.float16)\n",
        "    b = torch.randn((K, N), device=\"cuda\", dtype=torch.float16)\n",
        "    quantiles = [0.5, 0.2, 0.8]\n",
        "    if provider == \"cublas\":\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
        "            lambda: torch.matmul(a, b), quantiles=quantiles\n",
        "        )\n",
        "    if provider == \"triton\":\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
        "            lambda: matmul(a, b), quantiles=quantiles\n",
        "        )\n",
        "\n",
        "    return ms, max_ms, min_ms"
      ],
      "metadata": {
        "id": "NlhUaK_FsRxn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark.run(print_data=True, show_plots=True)"
      ],
      "metadata": {
        "id": "cBugObnDteg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}